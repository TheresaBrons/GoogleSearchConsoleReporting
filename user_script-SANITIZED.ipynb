{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script should grab the latest date that is already included in each table, then add in the missing dates\n",
    "#until the date is today-3.  It should do it for all search types, and eventually for the more accurate count data\n",
    "import glob\n",
    "from aux_scripts.GSC_API_extract import granular_extract\n",
    "from aux_scripts.insertion_csv_to_db import get_files, insert_files\n",
    "from aux_scripts.authorize_creds import authorize_creds\n",
    "from aux_scripts.low_performance_report import low_performers_report\n",
    "######################storage variables for database and desktop#######################################################\n",
    "#database variables\n",
    "#The searchType you input into a table should match the table name\n",
    "DATABASE_NAME=''\n",
    "PASSWORD =''\n",
    "USER = ''\n",
    "HOST = ''\n",
    "#I'm not actually sure if I'm using this variable anywhere.\n",
    "TABLE_NAMES=['web','image','video'] #tables where data is stored in db\n",
    "db_dict = {'USER':USER,'PASSWORD':PASSWORD,'HOST':HOST,'DATABASE_NAME':DATABASE_NAME,'TABLE_NAMES':TABLE_NAMES}\n",
    "\n",
    "#desktop variables\n",
    "#STORAGE_FOLDER is name of of the folder containing the 3 search type folders where csv data are currently stores\n",
    "STORAGE_FOLDER = '' \n",
    "\n",
    "#output folder will usually be same as storage folder, but you can store generated files in a different folder if you want\n",
    "OUTPUT_FOLDER = STORAGE_FOLDER\n",
    "#######################################################################################################\n",
    "\n",
    "#GSC API data #########################################################################################\n",
    "# credentials will not be changed by default in this file.  If you need to change them, call granular_extract with\n",
    "# the optional parameter cred_dict of the form {'creds':CLIENT_SECRETS_PATH,'authorized_creds_file':AUTHORIZED_CREDS_FILE}\n",
    "\n",
    "SC_SITE = '' #The site name you need to use to call GSC API using given credentials CREDS, below\n",
    "\n",
    "#the earliest date you'll draw from.  My script won't let you query for a date if it's already contained in the \n",
    "# storage_folder/search_type/ folder, though (these are parameters for aux_scripts.GSC_API_extract.granular_extract)\n",
    "NUM_DAYS = 485              # Number of Days, Months to Extract with api, at maximum.  496 is maximum, 3 is min\n",
    "#warning: NUM_DAYS only refers to api actions, not inserting files into db\n",
    "SEARCH_TYPES = ['web']#,'image','video'] #list of the table names and the corresponding GSC search types.  Names are the same\n",
    "gsc_dict={'sc_site':SC_SITE, 'num_days':NUM_DAYS,\n",
    "          'search_types':SEARCH_TYPES, 'storage_folder':STORAGE_FOLDER,'output_folder': OUTPUT_FOLDER}\n",
    "\n",
    "#################################variable definition complete#################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW we generate a report detailing low performing, high impression pages and their queries\n",
    "#might want to update database first, because this only examines things already in it!!!\n",
    "report_table_names=['acc_web','acc_image','acc_video'] #tables where data is stored in db\n",
    "report_db_dict = db_dict.copy()\n",
    "report_db_dict['TABLE_NAMES']=report_table_names\n",
    "low_performers_report(report_db_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserts things into the database\n",
    "granular_extract(gsc_dict, acc = False, to_save = True) \n",
    "#acc=True if you don't want query data\n",
    "#to_save = false if you don't want more than one day's worth of data\n",
    "#this script doesn't WORK! IF ITS THE ACC DATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserts things into the database\n",
    "granular_extract(gsc_dict, acc = False, to_save = True) \n",
    "#acc=True if you don't want query data\n",
    "#to_save = false if you don't want more than one day's worth of data\n",
    "#this script doesn't WORK! IF ITS THE ACC DATA!\n",
    "\n",
    "\n",
    "do_date_check = True\n",
    "print('do_date_check is ',do_date_check)\n",
    "restrict_to_num_days = True #use if you only want to insert the latest few files into db\n",
    "\n",
    "for i in range(len(gsc_dict['search_types'])):\n",
    "    #WARNING: TABLE NAMES and SEARCH TYPES should correspond, by index\n",
    "    #inserts data from the 'table' subfolder of granular/ into the table 'table' in the database \n",
    "    \n",
    "    #first, get file names\n",
    "    files = get_files(STORAGE_FOLDER, gsc_dict['search_types'][i])\n",
    "\n",
    "    if restrict_to_num_days == True:\n",
    "        \n",
    "        insert_files(files[-NUM_DAYS:], db_dict, db_dict['TABLE_NAMES'][i], do_date_check)\n",
    "    else:\n",
    "        insert_files(files, db_dict, db_dict['TABLE_NAMES'][i], do_date_check)  \n",
    "        \n",
    "#NOW we generate a report detailing low performing, high impression pages and their queries\n",
    "report_table_names=['acc_web','acc_image','acc_video'] #tables where data is stored in db\n",
    "report_db_dict = db_dict.copy()\n",
    "report_db_dict['TABLE NAMES']=report_table_names\n",
    "low_performers_report(report_db_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
