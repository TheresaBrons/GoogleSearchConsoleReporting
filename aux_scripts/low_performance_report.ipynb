{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "experienced-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from GSC_API_extract import granular_extract\n",
    "from insertion_csv_to_db import get_files, insert_files\n",
    "from authorize_creds import authorize_creds\n",
    "from datetime import date, timedelta, datetime\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "######################storage variables for database and desktop#######################################################\n",
    "#database variables\n",
    "#The searchType you input into a table should match the table name\n",
    "\n",
    "REPORTS_DIR = ''\n",
    "\n",
    "def query_to_df(query, db_dict, verbose=False):\n",
    "    cnx = mysql.connector.connect(user=db_dict['USER'], password=db_dict['PASSWORD'],\n",
    "                          host=db_dict['HOST'],\n",
    "                          database=db_dict['DATABASE_NAME'])\n",
    "    if verbose == True:\n",
    "        print(\"connected to server\")\n",
    "    cursor = cnx.cursor()\n",
    "    if verbose == True:\n",
    "        print(\"cursor has been defined, now executing query: \", query)\n",
    "    cursor.execute(query)\n",
    "    if verbose == True:\n",
    "        print(\"query has been executed, cursor is fetching all.\")\n",
    "    rows = cursor.fetchall()\n",
    "    if verbose == True:\n",
    "        print(\"rows have been fetched\")\n",
    "    df= pd.DataFrame(data = rows, columns = [i[0] for i in cursor.description]) \n",
    "    df=data_format(df)\n",
    "    cnx.close()\n",
    "    try:\n",
    "        if df['page'][0][0:4]=='http':\n",
    "            df['page'] = df['page'].apply(lambda x : x[28:])\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "def data_format(df):\n",
    "    for col in df.columns:\n",
    "    #this is because I don't have a function to convert the mysql data type to a pandas one!\n",
    "        try:\n",
    "            if col == 'clicks':\n",
    "                df[col] = df[col].apply(lambda x : int(x))\n",
    "            else:\n",
    "                df[col] = df[col].apply(lambda x : float(x))\n",
    "        except:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "def recent_low_performers(table_name, start_date):\n",
    "\n",
    "    print('pulling records from {} onwards'.format(start_date))\n",
    "    \n",
    "    recent_low_performers = r'''SELECT * FROM (SELECT page, sum(impressions) as impressions, sum(clicks) AS clicks, \n",
    "        AVG(ctr) AS avg_ctr, avg(position) as avg_position\n",
    "    FROM {0} WHERE date > \"{1}\"  GROUP BY page) as s\n",
    "    WHERE s.clicks < 100 and s.avg_position > 10 and s.impressions >100\n",
    "    GROUP BY s.page\n",
    "    ORDER BY s.impressions DESC\n",
    "    LIMIT 250;'''.format(table_name, start_date)\n",
    "    return query_to_df(recent_low_performers, db_dict)\n",
    "\n",
    "def low_performers_report(db_dict, tables = ['acc_web','acc_image','acc_video'], reports_dir = \n",
    "                        REPORTS_DIR, get_queries=True, days_period=30):\n",
    "    df_list=[]\n",
    "    \n",
    "    end_date=datetime.today()-timedelta(3)\n",
    "    start_date=end_date- timedelta(days_period)\n",
    "    end_date=datetime.strftime(end_date,'%Y-%m-%d')\n",
    "    start_date=datetime.strftime(start_date,'%Y-%m-%d')\n",
    "    print('start date is ', start_date)\n",
    "    print('end date is ', end_date)\n",
    "    \n",
    "    for table in tables:\n",
    "        df=recent_low_performers(table, start_date)\n",
    "        df=data_format(df)\n",
    "        df_list.append(df)\n",
    "        \n",
    "    report_name= reports_dir+'low performers report {}.xlsx'.format(end_date)\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(report_name, engine='xlsxwriter')\n",
    "    \n",
    "    for i in range(len(tables)):\n",
    "        if tables[i][:4]=='acc_':\n",
    "            tables[i]=tables[i][4:]\n",
    "            \n",
    "    if get_queries == True:\n",
    "\n",
    "        #having removed 'acc_' from table names, the resulting table name refers to a table with query data\n",
    "        for i in range(len(df_list)):\n",
    "            qdf=query_report(df_list[i],db_dict, table=tables[i], start_date=start_date, end_date = end_date)\n",
    "            print('appending qdf ', tables[i], ' to df_list')\n",
    "            df_list.append(qdf)\n",
    "            tables.append(tables[i] + \"_queries\")\n",
    "\n",
    "\n",
    "    for i in range(len(tables)):\n",
    "        # Convert the dataframe to an XlsxWriter Excel object.\n",
    "        df_list[i].to_excel(writer, sheet_name = tables[i], index=False)\n",
    "        \n",
    "        #workbook  = writer.book\n",
    "        \n",
    "        worksheet = writer.sheets[tables[i]]\n",
    "        for j in range(len(df_list[i].columns)):\n",
    "            worksheet.set_column(j, j, len(df_list[i].columns[j]))\n",
    "        \n",
    "    writer.save()\n",
    "    writer.close() #if you don't close it, it stays open via ipynb until you restart kernel.\n",
    "    return\n",
    "    \n",
    "def query_report(df,db_dict, table='web',impressions_col='impressions', start_date='', end_date = '',\n",
    "                 page_col='page', date_col = 'date', site='https://whoareyoumadeof.com/'):\n",
    "    #Returns a df listing all queries for which the pages with over 1k impressions rank, grouped by page, query.\n",
    "    #You can restrict the dates, start_date inclusive, end_date exclusive.\n",
    "    #start_date, end_date, page_col, impressions_col are strings. eg: '2020-01-01', 'page', and 'sum_impressions'\n",
    "    page_string = ''\n",
    "    \n",
    "    for page in df[page_col]:\n",
    "        page_string += '''\"{}\",'''.format(site+page)\n",
    "    page_string = page_string[:-1]\n",
    "    \n",
    "    if any([start_date, end_date]):\n",
    "        date_restriction = \"AND \" \n",
    "    if all([start_date, end_date]):\n",
    "        date_restriction +=  \" date >= '\" + start_date + \"' and \" + \"date < '\"+ end_date + \"'\"\n",
    "    elif any([start_date, end_date]):\n",
    "        date_restriction += \" date >= {}\".format(start_date) + \"date < \"+ end_date\n",
    "    else:\n",
    "        date_restriction = \"\"\n",
    "\n",
    "    df = df[df[impressions_col]>=1000]\n",
    "    #for each page receiving more than 1k impressions, include it in a list\n",
    "    query_report='''SELECT page, query, sum(impressions) as impressions, sum(clicks) as clicks, avg(position) as avg_position \n",
    "        FROM {0}\n",
    "        WHERE page in ({1}) {2}\n",
    "        GROUP BY page, query ORDER BY page, impressions DESC;'''.format(table, page_string, date_restriction)\n",
    "    \n",
    "    query_df=query_to_df(query_report, db_dict)\n",
    "    return query_df[query_df['impressions']>10]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
